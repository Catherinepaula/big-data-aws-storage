ğŸ—„ï¸ Big Data AWS Storage
Pipeline de dados com AWS S3, IAM e Athena utilizando Python e Boto3 â€” com foco em particionamento e orientaÃ§Ã£o Ã  coluna.

ğŸ“Œ Sobre o projeto
Este projeto implementa um pipeline completo de armazenamento e consulta de dados em nuvem, utilizando o dataset de crimes de Chicago (2014). O objetivo Ã© demonstrar boas prÃ¡ticas de armazenamento de dados em escala, com particionamento eficiente e consultas otimizadas via SQL.

ğŸ› ï¸ Tecnologias utilizadas

Python â€” processamento e automaÃ§Ã£o
Pandas â€” leitura e transformaÃ§Ã£o dos dados
Apache Parquet â€” formato colunar com compressÃ£o Snappy
Boto3 â€” SDK Python para AWS
AWS S3 â€” armazenamento dos dados em CSV e Parquet
AWS IAM â€” gerenciamento de usuÃ¡rios e permissÃµes
AWS Athena â€” consultas SQL serverless sobre os dados no S3


ğŸ—‚ï¸ Estrutura do projeto
big-data-aws-storage/
â”‚
â”œâ”€â”€ notebook.ipynb        # Pipeline completo
â”œâ”€â”€ README.md             # DocumentaÃ§Ã£o

ğŸ”„ Pipeline
crime.csv
    â”‚
    â–¼
DataFrame Pandas
    â”‚
    â”œâ”€â”€ CriaÃ§Ã£o da coluna reference_date (YYYY-MM)
    â”‚
    â”œâ”€â”€ PersistÃªncia em CSV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º S3 (Bucket CSV)
    â”‚
    â””â”€â”€ PersistÃªncia em Parquet â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º S3 (Bucket Parquet)
              (Snappy + particionado)
                    â”‚
                    â–¼
              AWS Athena
         (tabela externa + SQL)

ğŸ“Š Consultas SQL executadas
#ConsultaDescriÃ§Ã£o1SHOW PARTITIONSPartiÃ§Ãµes disponÃ­veis na tabela2COUNT(1)Total de registros (548.846)3GROUP BY reference_dateTotal de crimes por mÃªs4WHERE reference_date = '2014-01'Crimes em Janeiro/2014 por tipo5CASE WHEN arrest = trueTaxa de prisÃ£o por tipo de crime

ğŸ’¡ Destaques tÃ©cnicos

Particionamento por reference_date â€” reduz o volume de dados escaneados pelo Athena em filtros por perÃ­odo, diminuindo custo e tempo de resposta
CompressÃ£o Snappy â€” equilÃ­brio entre velocidade de leitura e taxa de compressÃ£o
MSCK REPAIR TABLE â€” carrega automaticamente as partiÃ§Ãµes existentes no S3
Infraestrutura como cÃ³digo â€” todos os recursos AWS criados via Boto3 (sem uso do console)


ğŸ“ˆ Resultado

548.846 registros processados
12 partiÃ§Ãµes criadas (uma por mÃªs de 2014)
28.8% taxa mÃ©dia de prisÃ£o nos crimes registrados


â–¶ï¸ Como executar

Clone o repositÃ³rio
Abra o notebook.ipynb no Google Colab
Configure suas credenciais AWS na cÃ©lula de configuraÃ§Ã£o
Execute as cÃ©lulas em ordem


ğŸ‘©â€ğŸ’» Autora
Catherine Paula Chitolina Cornelio
